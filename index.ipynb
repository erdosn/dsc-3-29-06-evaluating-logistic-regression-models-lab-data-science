{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Logistic Regression Models - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "As we saw with KNN, we need alternative evaluation metrics to determine the effectiveness of classification algorithms. In regression, we were predicting values so it made sense to discuss error as a distance of how far off our estimates were. In classifying a binary variable however, we are either correct or incorrect. As a result, we tend to deconstruct this as how many false positives versus false negatives we come across.  \n",
    "In particular, we examine a few different specific measurements when evaluating the performance of a classification algorithm. In this review lab, we'll review precision, recall and accuracy in order to evaluate our logistic regression models.\n",
    "\n",
    "\n",
    "## Objectives\n",
    "You will be able to:  \n",
    "* Understand and assess precision recall and accuracy of classifiers\n",
    "* Evaluate classification models using various metrics\n",
    "\n",
    "## Terminology Review  \n",
    "\n",
    "Let's take a moment and review some classification evaluation metrics:  \n",
    "\n",
    "\n",
    "$Precision = \\frac{\\text{Number of True Positives}}{\\text{Number of Predicted Positives}}$    \n",
    "  \n",
    "\n",
    "$Recall = \\frac{\\text{Number of True Positives}}{\\text{Number of Actual Total Positives}}$  \n",
    "  \n",
    "$Accuracy = \\frac{\\text{Number of True Positives + True Negatives}}{\\text{Total Observations}}$\n",
    "\n",
    "![](./images/Precisionrecall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At times, we may wish to tune a classification algorithm to optimize against precison or recall rather then overall accuracy. For example, imagine the scenario of predicting whether or not a patient is at risk for cancer and should be brought in for additional testing. In cases such as this, we often may want to cast a slightly wider net, and it is much preferable to optimize for precision, the number of cancer positive cases, then it is to optimize recall, the percentage of our predicted cancer-risk patients who are indeed positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "df = pd.read_csv('./heart.csv')\n",
    "df.head()\n",
    "X = df.drop('target', axis=1)\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a standard logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write a function to calculate the precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_hat, y):\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    for actual, pred in zip(y, y_hat):\n",
    "        # calculate positives first\n",
    "        if pred == 1:\n",
    "            if actual == 1:\n",
    "                TP += 1\n",
    "            if actual == 0:\n",
    "                FP += 0\n",
    "        # calculate negatives\n",
    "        if pred == 0:\n",
    "            if actual == 0:\n",
    "                TN += 1\n",
    "            if actual == 1:\n",
    "                FN += 1\n",
    "    \n",
    "    numerator = TP\n",
    "    denominator = TP + FN\n",
    "    return float(numerator)/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write a function to calculate the recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precison(y_hat, y):\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    for actual, pred in zip(y, y_hat):\n",
    "        # calculate positives first\n",
    "        if pred == 1:\n",
    "            if actual == 1:\n",
    "                TP += 1\n",
    "            if actual == 0:\n",
    "                FP += 0\n",
    "        # calculate negatives\n",
    "        if pred == 0:\n",
    "            if actual == 0:\n",
    "                TN += 1\n",
    "            if actual == 1:\n",
    "                FN += 1\n",
    "    \n",
    "    numerator = TP\n",
    "    denominator = TP + FP\n",
    "    return float(numerator)/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write a function to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    for actual, pred in zip(y, y_hat):\n",
    "        # calculate positives first\n",
    "        if pred == 1:\n",
    "            if actual == 1:\n",
    "                TP += 1\n",
    "            if actual == 0:\n",
    "                FP += 0\n",
    "        # calculate negatives\n",
    "        if pred == 0:\n",
    "            if actual == 0:\n",
    "                TN += 1\n",
    "            if actual == 1:\n",
    "                FN += 1\n",
    "    \n",
    "    numerator = TP + TN\n",
    "    denominator = TP + TN + FP + FN\n",
    "    return float(numerator)/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_hat, y):\n",
    "    r = recall(y_hat, y)\n",
    "    p = precison(y_hat, y)\n",
    "    \n",
    "    numerator = r*p*2\n",
    "    denominator = p + r\n",
    "    return float(numerator)/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate the precision, recall and accuracy of your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = clf.predict_proba(X_train)\n",
    "y_hat_test = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16240531, 0.83759469],\n",
       "       [0.04638682, 0.95361318],\n",
       "       [0.9767811 , 0.0232189 ],\n",
       "       [0.96895777, 0.03104223],\n",
       "       [0.41447407, 0.58552593]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_hat_thresh(y_hat_probs, thresh=0.50):\n",
    "    y_hats = []\n",
    "    for y in y_hat_probs:\n",
    "        if y[1] >= thresh:\n",
    "            y_hats.append(1)\n",
    "        else:\n",
    "            y_hats.append(0)\n",
    "    return np.array(y_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = clf.predict_proba(X_train)\n",
    "y_hat_test = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = y_hat_thresh(y_hat_train, thresh=0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do this for both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5409836065573771\n",
      "0.7021276595744682\n",
      "0.7488789237668162\n"
     ]
    }
   ],
   "source": [
    "print(precison(y_hat_train, y_train))\n",
    "print(recall(y_hat_train, y_train))\n",
    "print(f1_score(y_hat_train, y_train))\n",
    "print(accuracy(y_hat_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,   4],\n",
       "       [ 56,  66]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_train, y_hat_train)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a190f5208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, cmap=sns.color_palette('Blues'), annot=True, fmt='0.16g')\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing Precision Recall and Accuracy of Test vs Train Sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the precision, recall and accuracy for test and train splits using different train set sizes. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importimport  matplotlib.pyplotmatplot  as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_Precision = []\n",
    "testing_Precision = []\n",
    "training_Recall = []\n",
    "testing_Recall = []\n",
    "training_Accuracy = []\n",
    "testing_Accuracy = []\n",
    "\n",
    "for i in range(10,95):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= None) #replace the \"None\" here\n",
    "    logreg = LogisticRegression(fit_intercept = False, C = 1e12)\n",
    "    model_log = None\n",
    "    y_hat_test = None\n",
    "    y_hat_train = None\n",
    "\n",
    "# 6 lines of code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3 scatter plots looking at the test and train precision in the first one, test and train recall in the second one, and testing and training accuracy in the third one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for test and train precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for test and train recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for test and train accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Nice! In this lab, you gained some extra practice with evaluation metrics for classification algorithms. You also got some further python practice by manually coding these functions yourself, giving you a deeper understanding of how they work. Going forward, continue to think about scenarios in which you might prefer to optimize one of these metrics over another."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
